include: "config.sk"

# ######
#
# Lists all available rules (snakemake -l) but also gives more
# information such as the file in which the rule is found.
#
explain_rule_fields = ['name', 'wildcard_names', '_wildcard_constraints', 'snakefile']
rule explain_rules:
    run:
        print('\t|\t'.join([_rule_field.upper() 
                           for _rule_field in explain_rule_fields
                        ]))
        for _rule in rules.__dict__.keys():
            print('\t|\t'.join([str(rules.__dict__[_rule].__dict__[_rule_field]) 
                                  for _rule_field in explain_rule_fields
                            ]))

rule explain_link_fastq_read:
    run:
        for _elem in rules.__dict__['fastq__link_fastq_read'].__dict__.keys():
            print("{}:{}{}".format(_elem, os.linesep, rules.__dict__['fastq__link_fastq_read'].__dict__[_elem]))

localrules: pbs_dir, update_cluster_rules
rule pbs_dir:
    output:
        primary= {PBS_DIR}
    shell:"""
      mkdir -p {PBS_DIR}
    """ 

yaml = "cluster.yaml"
rule update_cluster_rules:
    #
    # Looks for all the pipeline's available rules write default cluster configuration
    # in the 'yaml' file.
    #
    #output: primary = yaml
    run:
        shell("""
      ## Update default:
      if [ ! -f "{yaml}" ] || ! grep -s -q "^__default__:" "{yaml}"; then
        cat << HERE > "{yaml}"
__default__:
  name: '{tmp_name}'
  select: 1
  ncpus: 1
  mem: '1gb'
  error: '{tmp_primary}.pbs.err' 
  output: '{tmp_primary}.pbs.out'
HERE
      fi

      # Update rules if not here
      for _rule in {_rules}; do
        grep -s -q "^$_rule" "{yaml}" \
         || cat << HERE >> "{yaml}"
$_rule:
  do: True
HERE
      done
    """.format(yaml=yaml, _rules=" ".join(rules.__dict__.keys()), 
               tmp_name = "{{config[project][type]}}",
               tmp_primary = "{{output.primary}}"
    ))

# ---------------
# Metadata file
# ---------------
rule f2_metadata_project:
    output: 
        primary= "{prefix}f2-metadata_{prj_name}.{format}"
    wildcard_constraints: 
        prefix=".*"

    shell:"""
      #prj_name="Landsberger_359_CDKL5"
      URL_F2="http://172.21.156.25:8000"
      URL_F2="http://172.25.50.69:8001"
      URL_PROJECTS="${{URL_F2}}/projects"
      URL_SQC_RUN="${{URL_PROJECTS}}/api/sequencing_run"
      URL_TO_DEMUX="${{URL_SQC_RUN}}/to_demultiplex/"
      
      curl "${{URL_PROJECTS}}/{wildcards[prj_name]}.{wildcards[format]}" \
       > {output[primary]}
      
    """

rule f2_metadata:
    #input: # Should we get the default project name (bit.which-prj) and link it?
    #    "{prefix}f2-metadata_project.{format}
    output: 
        primary= "{prefix}f2-metadata.{format}"
    wildcard_constraints: 
        prefix=".*"

    shell:"""
      prj_name=$(bit.which-prj) #Landsberger_359_CDKL5"
      URL_F2="http://172.21.156.25:8000"
      URL_F2="http://172.25.50.69:8001"
      URL_PROJECTS="${{URL_F2}}/projects"
      URL_SQC_RUN="${{URL_PROJECTS}}/api/sequencing_run"
      URL_TO_DEMUX="${{URL_SQC_RUN}}/to_demultiplex/"
      
      curl "${{URL_PROJECTS}}/${{prj_name}}.{wildcards[format]}" \
       > {output[primary]}
      
    """

# -----------------------
# Rules Bulk Processing
# -----------------------
rule all_chunks:
    input: 
        fastq_map= fastq_samples_map,
        bams= lambda wildcards: csvmap__format_str_from_query_dict(
                  csvmap=fastq_csvmap, 
                  str_format=chunk_fastq_format, 
                  **wildcards)
    output: 
        primary= "all_chunks{preprocesses}.done"
    shell:"""
      touch {output}
    """

rule all_samples:
    input: 
        fastq_map= fastq_samples_map,
        bams= lambda wildcards: csvmap__format_str_from_query_dict(
                  csvmap=fastq_csvmap, 
                  str_format=merged_bam_format, 
                  **wildcards)
    output: 
        primary= "all_samples{preprocesses}.done"
    shell:"""
      touch {output}
    """
