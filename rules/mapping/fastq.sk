# ---------------------
# Mapping fastq files
# ---------------------
# We first need to define our csv mapper by specifying the column names:
fastq_csvmap = csvh.CsvMap('fastq_samples.map', delimitor='\t', colnames=fastq_helper.FastqFile.get_field_names()) 
fastq_map_sep = "\t"
fastq_samples_map = "fastq_samples.map"

rule fastq__fastq_files:
    #
    # Find all the fastq files in the RUN dirctories found in configuration.
    #
    output: 
        primary= "fastq_files.txt"
    shell:"""
      find {RAW_DATA_DIRS} -name '*.fastq.gz' > {output}
    """ 

def get_run_from_filepath(filename):
    #
    # Retrieve a Run id from a file containing paths.
    #
    for _run in RUN_IDS:
        run_path = os.sep.join([RUN_BASEDIR, _run, ''])
        if filename.startswith(run_path):
            return _run
        else:
           continue

rule fastq__fastq_samples:
    #   
    # Maps all the illumina filename metadata in a file.
    #   
    input: 
        file="fastq_files.txt"
    output: 
        primary="fastq_samples.map"
    run:
        with open(input['file'], 'r') as files:
            for _file in files:
                ## Deduce file's run name
                sample_run = get_run_from_filepath(_file)

                ## Get file's info
                fastqfile = fastq_helper.FastqFile(_file.strip(), run_name=sample_run)

                ## Write to output
                with open(output['primary'], 'a') as fmap:
                    fmap.write("{}{}".format(fastq_map_sep.join(
                      [fastqfile.__dict__[_field] \
                        for _field in list(fastq_helper.FastqFile.get_field_names())
                      ]   
                     ), os.linesep))


# -----------------
# Link fastq reads
# -----------------
localrules: fastq__link_fastq_read
rule fastq__link_fastq_read:
    #
    # Links original fastq file to the project directory.
    #
    input:
        #samples_map = fastq_samples_map,
        fastq_read= lambda wildcards: csvmap__format_str_from_query_dict(
                  csvmap=fastq_csvmap, 
                  str_format="{sample_path}",
                  **wildcards)
    output: 
        primary=chunk_fastq_format + ".fastq.gz"
    shell:"""
      ln.rel {input[fastq_read]} {output[primary]} 
    """


# ---------------
# Fastq Quality
# ---------------
FASTQC_CORES = 6
rule fastq__fastqc_file:
    input:
        fastq_in= "{prefix}.fastq.gz"
    output:
        primary= "{prefix}.fastqc.html"
    shell:"""
      fastqc -o $(dirname {input[fastq_in]}) -t {FASTQC_CORES} {input[fastq_in]}
    """ 


# -----------------
# Fastq Trimming
# -----------------
rule fastq__fasta_adapters:
    input: 
        adapter_fasta="/lustre1/genomes/Illumina_Adapters/Adapters.fasta"
        # SUGGESTION: set an ADAPTER_FASTA_PATH variable in config.sk (everything that has hardcoded paths actually)
    output:
        primary="adapters.fa"
    shell:"""
      condactivate
      ## Substitute uracil in timin; Remove empty lines.
      perl -pe 'if(!m/^>/){{ tr/U/T/}}' {input[adapter_fasta]} \
       | grep . > {output[primary]}.tmp1
      reverse_fasta < {output[primary]}.tmp1 \
       | perl -lpe 'if(m/^>/){{$_=$_."_reverse"}}' \
       > {output[primary]}.tmp2
      cat {output[primary]}.tmp1 {output[primary]}.tmp2 \
       > {output[primary]}
      rm {output[primary]}.tmp1 {output[primary]}.tmp2
    """

TRIMMED = '.cutadapt' #'.trimmomatic'
## TRIMMING with trimmomatic
# SUGGESTION: 
#  v Rename variable in TRIMMOMATIC_CMD -> clarity in variable names.
#  - Hardcoded paths go in config.sk file
#  - Make a single uniform rule for trimmomatic by managing the paired condition in the input.
TRIMMOMATIC_CMD="trimmomatic-0.32.jar"
TRIMMOMATIC_RAM = '10gb'     # *in GB* 
TRIMMOMATIC_RAM_JAVA = '10240M'    # *in MB; = TRIMMOMATIC_RAM*1024*
TRIMMOMATIC_PAIRED = 'PE' if PAIRED in ['Y', True] else 'SE'
TRIMMOMATIC_HEADCROP = 'HEADCROP:12'        # for QUANTSEQ, leave empty for TruSeq #

rule fastq__trimmomatic_fastq:
    input: 
        fastq_file = "{prefix}.fastq.gz",
        adapter = "adapters.fa"
    output: 
        primary = "{prefix}.trimmomatic.fastq.gz"
    shell:"""
      java -Djava.io.tmpdir=$TMPDIR -Xmx{TRIMMOMATIC_RAM_JAVA} \
        -jar {TRIMMOMATIC_CMD} {TRIMMOMATIC_PAIRED} \
        -phred33 \
        -trimlog {output[primary]}.log \
        {input[fastq_file]} \
        {output[primary]} \
        ILLUMINACLIP:{input[adapter]}:2:30:10 \
        LEADING:3 \
        TRAILING:3 \
        SLIDINGWINDOW:4:15 \
        MINLEN:15 \
        {TRIMMOMATIC_HEADCROP} \
        > {output[primary]}.out
      #touch {output} # DRY_RUN
    """

ruleorder: fastq__trimmomatic_fastq > fastq__cutadapt_fastq > fastq__link_fastq_read
## TRIMMING with cut_adapt 
CUTADAPT_B=" -b file:adapters.fa"  #CUT_ADAPTER
CUTADAPT_Q=" -q 30,30" #TRIM_Q
CUTADAPT_U=" -u 13" #TRIM_CUT
CUTADAPT_M=" -m 15" #TRIM_MIN_LEN  # Let always set to avoid read without sequence after trimming
rule fastq__cutadapt_fastq:
    input:
        fastq_file = "{prefix}.fastq.gz",
        adapter = "adapters.fa"
    output: 
        primary = "{prefix}.cutadapt.fastq.gz"
    shell:"""
      condactivate  # >  {output[primary]}.out # DRY_RUN
      cutadapt {CUTADAPT_B} \
        --trim-n {CUTADAPT_Q} \
        {CUTADAPT_U} \
        {CUTADAPT_M} \
        -o {output[primary]} \
        {input[fastq_file]} \
       > "{output[primary]}.log"
      #touch {output} # DRY_RUN
    """

# ----------
# All fastq
# ----------
#rule bam__all_bam_chunks:
#    input: 
#        fastq_map= fastq_samples_map,
#        bams= lambda wildcards: csvmap__format_str_from_query_dict(
#                  csvmap=fastq_csvmap, 
#                  str_format="BAM/{sample_name}{preprocesses}.bam", 
#                  **wildcards)
#    output: 
#        primary= "all_bam_chunks{preprocesses}.done"
#    shell:"""
#      touch {output}
#    """
