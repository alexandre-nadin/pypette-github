include: 'bam.py'
pipeman.includeModule("genomes/genome.sk")
pipeman.includeModule("genomes/gencode.sk")
pipeman.includeModule("genomes/exome.sk")

""" Allowed Sorting Processes """
sortingTools = ('picard', 'samtools')
pipeman.updateWildcardConstraints(
  procSorted = "(sorted/({})/)?".format("|".join(sortingTools)),
  procMarkDup = "(markdup/)?",
)

bam__mappingDir   = fastq__sampleRunDir + "/" + fastq__procs + "mapped" + bam__alignerDir(append=True)
bam__samplePrefix = bam__mappingDir + "/{sample_name}"
bam__sample       = bam__samplePrefix + ".bam"

""" Sample Run Reads Output Targets """
bam__relDir       = "mapped" + bam__alignerDir(append=True)
bam__sampleDir    = fastq_merge__dir + "/{procTrimming}" + bam__relDir

##
# General IO (on any bam file).
bam__sortedSamplePrefix = bam__sampleDir + bam__sorterDir(append=True) + "/{sample_name}"
bam__sortedSample = bam__sortedSamplePrefix + ".bam"

""" Sample Merged Bams Output Targets """
bam__pipelineDir = "fastq/all/{procTrimming}" + bam__relDir + "/merged/{procSorted}{procMarkDup}"
bam__mergedSampleDir    = "samples/{sample_name}/" + bam__pipelineDir 
bam__mergedSamplePrefix = bam__mergedSampleDir + "{sample_name}"
bam__mergedSample       = bam__mergedSamplePrefix + ".bam"
bam__mergedSampleStats  = bam__mergedSamplePrefix + ".bamstats"

# Note: Include the aligner found in pipeline configuration file after this
#       file's variables, as aligner's rules should depend on the variables 
#       declared above.
bam__includeAlignerModule()

# -----------------
# Mark Duplicates
# -----------------
bam__sampleMarkdupPrefix = "{anyprefix}markdup/{sample_name}"
rule bam__markDuplicates:
  input: 
    bam     = "{anyprefix}{sample_name}.bam"
  output: 
    bam     = bam__sampleMarkdupPrefix + ".bam",
    bai     = bam__sampleMarkdupPrefix + ".bai",
    metrics = bam__sampleMarkdupPrefix + ".metrics"
  run:
    cmd = """
      picard MarkDuplicates                           \
      I={input.bam}                                   \
      O={output.bam}                                  \
      CREATE_INDEX=true                               \
      VALIDATION_STRINGENCY=SILENT                    \
      REMOVE_DUPLICATES=false                         \
      ASSUME_SORTED=true                              \
      METRICS_FILE={output.metrics}                    
    """
    texshell(**vars())

# --------------
# Sorting Bams
# --------------
rule bam__sortSamplePicard:
  input:  "{anyprefix}{sample_name}.bam"
  output: "{anyprefix}sorted/picard/{sample_name}.bam",
  run:
    cmd = """
      picard SortSam          \
        I={input}             \
        SORT_ORDER=unsorted   \
        O={output}
    """
    texshell(**vars())

rule bam__sortSampleSamtools:
  input:  "{anyprefix}{sample_name}.bam"
  output: "{anyprefix}sorted/samtools/{sample_name}.bam"
  run:
    cmd = """
      samtools view -Su {input}    \
       | samtools sort -o {output}  
    """
    texshell(**vars())

ruleorder: samples__runs > bam__sampleStats > bam__sortSampleSamtools > bam__markDuplicates

# -----------
# Bam Stats
# -----------
rule bam__sampleStats:
  input:
    bam = "{someprefix}.bam"
  output:
    primary = "{someprefix}.bamstats"
  run:
    cmd = """
      bamtools stats       \
        -in {input.bam}    \
        > {output.primary}
    """
    texshell(**vars())

ruleorder: samples__all > bam__sampleStats

# ------------
# Merge BAMs
# ------------
ruleorder: bam__markDuplicates > bam__sortSamplePicard > bam__sortSampleSamtools > bam__mergeSample
rule bam__mergeSample:
  input:
    bam = lambda wildcards: 
      fastq__mapStringSamples(bam__sample, withResult=True, **wildcards)
  output:
    bam = temp("samples/{sample_name}/runs/all/fastq/" + fastq__procs + bam__relDir + "/merged/{sample_name}.bam")
  run:
    if len(input.bam) > 1:
      cmd = """
        picard MergeSamFiles                            \
          {merge_prefixes}                              \
          O={output.bam}                                \
          CREATE_INDEX=true                             \
          MSD=true                                      \
          TMP_DIR=$TMPDIR                               \
          VALIDATION_STRINGENCY=SILENT                  \
         > {output.bam}.log
      """
    else:
      cmd = """
        ln.rel -f {input.bam} {output.bam}
      """
    merge_prefixes = picardMergeInputString(input.bam)
    texshell(**vars())

ruleorder: bam__mergeSample > samples__runs

rule bam__makeIndex:
  input:  "{someprefix}.bam"
  output: "{someprefix}.bai"
  run:
    cmd = """
      picard BuildBamIndex I={input} O={output}
    """
    texshell(**vars())

rule bam__hsMetrics:
  input:  
    "{someprefix}.bam"
  output: 
    "{someprefix}_hsMetrics.txt"
  run:
    genomeFasta     = genome__fasta()
    baitIntervals   = exome__baitIntervals()
    targetIntervals = exome__targetIntervals()
    cmd = """
      picard CollectHsMetrics          \
        BI={baitIntervals}             \
        TI={targetIntervals}           \
        I={input}                      \
        O={output}                     \
        R={genomeFasta}                \
        VALIDATION_STRINGENCY=SILENT
    """
    texshell(**vars())

ruleorder: samples__all > bam__hsMetrics

# -------
# Counts
# -------
# Strandedness
#   0: unstranded
#   1: forward
#   2: reverse
# -t exon :  Explicitating default value. This way only reads on exons are counted, and then summarized at gene level (by default). If '-f' is used, summarization would be at feature level (=exon by exon).*
# -C      :  do NOT count chimeric fragments in PE data, i.e. paired reads mapping on different chromosomes *
# -R BAM  :  Annotates the original bam files. We don't need this bam for now *
rule bam__counts:
  input:
    bam = "{someprefix}/{sample_name}.bam",
    gtf = gencode__gtf()
  output:
    counts    = "{someprefix}/{sample_name}.counts",
    sumcounts = "{someprefix}/{sample_name}.counts.summary",
    bam       = "{someprefix}/{sample_name}.bam.annot"
  run: 
    paired   = '-p' if pipeman.config.project.pair_end else ''
    cores    = pipeman.config.pipeline.mapping.counter.cores
    stranded = 2
    cmd = """
      featureCounts               \
        --tmpDir $TMPDIR          \
        -T {cores}                \
        {paired}                  \
        -C                        \
        -s {stranded}             \
        -t exon                   \
        -F GTF                    \
        -a {input.gtf}            \
        -g gene_name              \
        -R BAM                    \
        -o {output.counts}        \
        {input.bam}               \
       2> {input}.subread.log
    """
    texshell(**vars())
