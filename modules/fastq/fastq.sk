from utils import csv_helper
from utils.fastq_helper import FastqFile
from utils.files import touch

# -------------------------------
# Wildcards Constraints
#
# Organization of the outputs follows a convention both in the naming of the 
# files as in their directories. As such, we define regex constraints on the rules' 
# wildcards. Those wildcards are defined outside of the rules, so they are 
# global to all the rules. Each constraint can then be overridden specifically 
# in the rule itself, the last declaration prevailing.
# -------------------------------------------------------------------
pipeman.updateWildcardConstraints(
  **FastqFile.regex_fields,
  preprocesses     = "(\.\w+)*?"
)

# --------------------- 
# I/O files format
#
# Convention: 
#   - {preprocesses} should be present both in the input and output. Can be empty.
#   - {process} is only for outputs as it is about the process defined by the
#     current rule.
# --------------------- 
fastq__base_fmt = "{prj_name}/fastq"
fastq__chunk_io = fastq__base_fmt + "/{sample_run}/{sample_name}/{sample_chunkname}{preprocesses}{sample_extension}"

# ---------------------
# Mapping fastq files
# ---------------------
def setConfigs(**kwargs):
  """
  Not elegant way to deal with config files.
  Should set dependence to cluster.yaml (retreived in {prj_name}/metadata.json)
  Loads {prj_name}/metadata.json.
  """
  import os
  """ Load cluster configuration """
  pipeman.config_manager.loadConfig(
    os.path.join(
      pipeman.dir_modules, "lims", "cluster.yaml"
    )
  )
  """ Load project metadata configuration """
  pipeman.config_manager.loadConfig(
    "{prj_name}/metadata.json".format(**kwargs)
  )

def fastq__getRuns():
  return [ 
    os.path.join(pipeman.config.cluster.sequencing_runs_dir, runid)
    for runid in pipeman.config.project.run_ids
  ]

def fastq__checkRuns(runs=[]):
  error = False
  for run in runs:
    if not os.path.isdir(run):
      pipeman.log.error("Run {} doesn't exist.".format(run))
      error = True
  if error: 
    raise

fastq__raw_files_io = "{prj_name}/fastq/raw_files.txt"
rule fastq__mapRawFiles:
  """
  Find all the fastq files in the RUN directories specified in the 
  configuration.
  """
  input:
    metadata = lims__project_metadata_io
  output: 
    primary  = fastq__raw_files_io
  run:
    setConfigs(**wildcards)
    runs = fastq__getRuns()
    fastq__checkRuns(runs)
    shell("""
      find {runs} -name '*.fastq.gz' > {output}
    """)

def getRunFromFilepath(filepath):
  """ 
  Retrieves a Run id from a file containing paths. 
  """
  for run in pipeman.config.project.run_ids:
    run_path = os.path.join(
      pipeman.config.cluster.sequencing_runs_dir,
      run, 
    )
    if filepath.startswith(run_path):
      return run
    else:
      continue

def mapFastqFilename(filename):
  """
  Maps the illumina metadata based on the given filename.
  """
  return [ 
    FastqFile(
      filename.strip(), 
      run_name= getRunFromFilepath(filename)
    ).__dict__[field]
     for field in list(FastqFile.fieldNames())
  ]   

fastq__mapped_samples_io     = fastq__base_fmt + "/samples{ext}"
fastq__mapped_samples_io_dft = fastq__base_fmt + "/samples.csv"
rule fastq__mapSamples:
  """   
  Maps all the illumina filenames' metadata in a file.
  """
  input: 
    file    = fastq__raw_files_io
  output: 
    primary = fastq__mapped_samples_io
  run:
    setConfigs(**wildcards)

    """ File Output Header """
    sample_lines = [ FastqFile.fieldNames() ]
    with open(input.file, 'r') as fastq_files:
      """ Mapped Samples Lines """
      sample_lines.extend(list(map(mapFastqFilename, fastq_files)))

    """ Write Output """
    with open(output.primary, 'a') as fmap:
      fmap.write(
        pipeman.samples.listsToSamplesheet(
          sample_lines, 
          pipeman.sampleExtensions[wildcards.ext]))

def fastq__loadSamples(**kwargs):
  if pipeman.samples.data is None:
    pipeman.samples.load(fastq__mapped_samples_io_dft.format(**kwargs))

def mapStringSamples(s, **kwargs):
  fastq__loadSamples(**kwargs)
  return pipeman.samples.buildStringFromKeywords(s, **kwargs)
  
# -----------------
# Link fastq reads
# -----------------
rule fastq__linkFastqReads:
  input: 
    fastq_files = lambda wildcards: 
      mapStringSamples(fastq__chunk_io, **wildcards)
  output: fastq__base_fmt + "/fastq__linkFastqReads.done"
  run:
    touch(output)

localrules: fastq__linkFastqRead
rule fastq__linkFastqRead:
  """
  Links original fastq file to the project directory.
  """
  input:
    fastq_read = lambda wildcards:
      mapStringSamples("{sample_path}", **wildcards)
  output: 
    primary    = fastq__chunk_io
  shell:"""
    ln.rel {input.fastq_read} {output.primary} 
  """

# ---------------
# Fastq Quality
# ---------------
FASTQC_CORES = 6
rule fastq__fastqc_file:
  input:
      fastq_in= "{prefix}.fastq.gz"
  output:
      primary= "{prefix}.fastqc.html"
  shell:"""
    fastqc -o $(dirname {input[fastq_in]}) -t {FASTQC_CORES} {input[fastq_in]}
  """ 
