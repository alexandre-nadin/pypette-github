from utils import csv_helper
from utils.fastq_helper import FastqFile

# -------------------------------
# Wildcards Constraints
#
# Organization of the outputs follows a convention both in the naming of the 
# files as in their directories. As such, we define regex constraints on the rules' 
# wildcards. Those wildcards are defined outside of the rules, so they are 
# global to all the rules. Each constraint can then be overridden specifically 
# in the rule itself, the last declaration prevailing.
# -------------------------------------------------------------------
wildcard_constraints:
  sample_name    = FastqFile.regex_fields.sample_name,
  sample_number  = FastqFile.regex_fields.sample_number,
  sample_lane    = FastqFile.regex_fields.sample_lane,
  sample_chunknb = FastqFile.regex_fields.sample_chunknb,
  sample_read    = FastqFile.regex_fields.sample_read,
  preprocesses   = "(\.\w+)*?"

# --------------------- 
# I/O files format
#
# Convention: 
#   - {preprocesses} should be present both in the input and output. Can be empty.
#   - {process} is only for outputs as it is about the process defined by the
#     current rule.
# --------------------- 
fastq__base_fmt = "{prj_name}/fastq"
#fastq__chunk_format="{sample_run}/{sample_name}/{sample_chunkname}{preprocesses}"
fastq__chunk_format = fastq__base_fmt + "/{sample_run}/{sample_name}/{sample_chunkname}{preprocesses}"

# ---------------------
# Mapping fastq files
# ---------------------
# We first need to define our csv mapper by specifying the column names:
fastq__csvmap = csv_helper.CsvMap('samples.csv', delimiter='\t', colnames=FastqFile.fieldNames()) 
fastq__map_sep = "\t"
fastq__samples_map = "samples.csv"

def setConfigs(**kwargs):
  """
  Not elegant way to deal with config files.
  Should set dependence to cluster.yaml (retreived in {prj_name}/metadata.json)
  Loads {prj_name}/metadata.json.
  """
  import os
  """ Load cluster configuration """
  pipeman.config_manager.loadConfig(
    os.path.join(
      pipeman.dir_modules, "lims", "cluster.yaml"
    )
  )
  """ Load project metadata configuration """
  pipeman.config_manager.loadConfig(
    "{prj_name}/metadata.json".format(**kwargs)
  )

def fastq__getRuns():
  return [ 
    os.path.join(pipeman.config.cluster.sequencing_runs_dir, runid)
    for runid in pipeman.config.project.run_ids
  ]

def fastq__checkRuns(runs=[]):
  error = False
  for run in runs:
    if not os.path.isdir(run):
      pipeman.log.error("Run {} doesn't exist.".format(run))
      error = True
  if error: 
    raise

fastq__raw_files_io = "{prj_name}/fastq/raw_files.txt"
rule fastq__rawFiles:
  """
  Find all the fastq files in the RUN directories specified in the 
  configuration.
  """
  input:
    metadata = lims__project_metadata_io
  output: 
    primary  = fastq__raw_files_io
  run:
    setConfigs(**wildcards)
    runs = fastq__getRuns()
    fastq__checkRuns(runs)
    shell("""
      find {runs} -name '*.fastq.gz' > {output}
    """)

def getRunFromFilepath(filepath):
  """ Retrieves a Run id from a file containing paths. """
  for run in pipeman.config.project.run_ids:
    run_path = os.path.join(
      pipeman.config.cluster.sequencing_runs_dir,
      run, 
    )
    if filepath.startswith(run_path):
      return run
    else:
      continue

def mapFastqFilename(filename):
  """
  Maps the illumina metadata based on the given filename.
  """
  return [ 
    FastqFile(
      filename.strip(), 
      run_name= getRunFromFilepath(filename)
    ).__dict__[field]
     for field in list(FastqFile.fieldNames())
  ]   

def listsToSamplesheet(listLines, delimiter):
  """
  Takes in a list of line lists and formats them to a Samplesheet output.
  """
  return os.linesep.join(delimiter.join(line) for line in listLines)

fastq__samples_io = "{prj_name}/fastq/samples{ext}"
rule fastq__samples:
  """   
  Maps all the illumina filenames' metadata in a file.
  """
  input: 
    file    = fastq__raw_files_io
  output: 
    primary = fastq__samples_io
  run:
    setConfigs(**wildcards)

    """ File Output Header """
    sample_lines = [ FastqFile.fieldNames() ]
    with open(input.file, 'r') as fastq_files:
      """ Mapped Samples Lines """
      sample_lines.extend(list(map(mapFastqFilename, fastq_files)))

    """ Write Output """
    with open(output.primary, 'a') as fmap:
      fmap.write(
        listsToSamplesheet(
          sample_lines, 
          pipeman.sampleExtensions[wildcards.ext]))

def csvmap__formatStrFromQueryDict(csvmap, str_format="", **query_dict):
    #
    # Queries a CSVMap object based on a given dictionary.
    #
    return set([ str_format.format(**_cmap)
                 for _cmap in csvmap.query_dict(**query_dict)
               ])

# -----------------
# Link fastq reads
# -----------------
localrules: fastq__linkFastqRead
rule fastq__linkFastqRead:
  #
  # Links original fastq file to the project directory.
  #
  input:
    #samples_map = fastq__samples_map,
    fastq_read = lambda wildcards: csvmap__format_str_from_query_dict(
                   csvmap=fastq__csvmap, 
                   str_format="{sample_path}",
                   **wildcards)
  output: 
    primary    = fastq__chunk_format + ".fastq.gz"
  shell:"""
    ln.rel {input.fastq_read} {output.primary} 
  """

# ---------------
# Fastq Quality
# ---------------
FASTQC_CORES = 6
rule fastq__fastqc_file:
  input:
      fastq_in= "{prefix}.fastq.gz"
  output:
      primary= "{prefix}.fastqc.html"
  shell:"""
    fastqc -o $(dirname {input[fastq_in]}) -t {FASTQC_CORES} {input[fastq_in]}
  """ 
