from utils import csv_helper
from utils.fastq_helper import FastqFile

# -------------------------------
# Wildcards Constraints
#
# Organization of the outputs follows a convention both in the naming of the 
# files as in their directories. As such, we define regex constraints on the rules' 
# wildcards. Those wildcards are defined outside of the rules, so they are 
# global to all the rules. Each constraint can then be overridden specifically 
# in the rule itself, the last declaration prevailing.
# -------------------------------------------------------------------
wildcard_constraints:
  sample_name    = FastqFile.regex_fields.sample_name,
  sample_number  = FastqFile.regex_fields.sample_number,
  sample_lane    = FastqFile.regex_fields.sample_lane,
  sample_chunknb = FastqFile.regex_fields.sample_chunknb,
  sample_read    = FastqFile.regex_fields.sample_read,
  preprocesses   = "(\.\w+)*?"

# --------------------- 
# I/O files format
#
# Convention: 
#   - {preprocesses} should be present both in the input and output. Can be empty.
#   - {process} is only for outputs as it is about the process defined by the
#     current rule.
# --------------------- 
fastq__chunk_format="{sample_run}/{sample_name}/{sample_chunkname}{preprocesses}"

# ---------------------
# Mapping fastq files
# ---------------------
# We first need to define our csv mapper by specifying the column names:
fastq__csvmap = csv_helper.CsvMap('fastq_samples.map', delimitor='\t', colnames=FastqFile.get_field_names()) 
fastq__map_sep = "\t"
fastq__samples_map = "fastq_samples.map"

def setConfigs(**kwargs):
  """
  Not elegant way to deal with config files.
  Should set dependence to cluster.yaml (retreived in {prj_name}/metadata.json)
  Loads {prj_name}/metadata.json.
  """
  import os
  """ Load cluster configuration """
  pipeman.config_manager.loadConfig(
    os.path.join(
      pipeman.dir_modules, "lims", "cluster.yaml"
    )
  )
  """ Load project metadata configuration """
  pipeman.config_manager.loadConfig(
    "{prj_name}/metadata.json".format(**kwargs)
  )

def fastq__getRuns():
  return [ os.path.join(pipeman.config.cluster.sequencing_runs_dir, runid)
    for runid in pipeman.config.project.run_ids
  ]

def fastq__checkRuns(runs=[]):
  error = False
  for run in runs:
    if not os.path.isdir(run):
      pipeman.log.error("Run {} doesn't exist.".format(run))
      noerror = True
  if error: raise

fastq__fastq_files_io = "{prj_name}/fastq/fastq_files.txt"
rule fastq__fastqFiles:
  """
  Find all the fastq files in the RUN dirctories found in configuration.
  """
  input:
    metadata = lims__project_metadata_io
  output: 
    primary  = fastq__fastq_files_io
  run:
    setConfigs(**wildcards)
    runs = fastq__getRuns()
    fastq__checkRuns(runs)
    shell("""
      find {runs} -name '*.fastq.gz' > {output}
    """)
def getRunFromFilepath(filepath):
  #
  # Retrieve a Run id from a file containing paths.
  #
  for run in pipeman.config.project.run_ids:
    run_path = os.path.join(
      pipeman.config.cluster.sequencing_runs_dir,
      run, 
    )
    print("'{}' starts with '{}'?".format(filepath, run_path))
    if filepath.startswith(run_path):
      print("  OK")
      return run
    else:
      print("  KO")
      continue


fastq__fastq_samples_io = "{prj_name}/fastq/fastq_samples.map"
rule fastq__fastqSamples:
  #   
  # Maps all the illumina filename metadata in a file.
  #   
  input: 
    file    = fastq__fastq_files_io
  output: 
    primary = fastq__fastq_samples_io
  run:
    setConfigs(**wildcards)
    with open(input.file, 'r') as files:
      for _file in files:
        ## Deduce file's run name
        sample_run = getRunFromFilepath(_file)

        ## Get file's info
        fastqfile = FastqFile(_file.strip(), run_name=sample_run)
        #fastqfile = FastqFile(_file.strip(), run_name=_file)

        ## Write to output
        with open(output.primary, 'a') as fmap:
          fmap.write("{}{}".format(
            fastq__map_sep.join(
              [ fastqfile.__dict__[_field]
                for _field in list(FastqFile.get_field_names())
              ]   
            ), 
            os.linesep))

rule fastq_reads:
  run:
    fastq_read = lambda wildcards: csvmap__format_str_from_query_dict(
                   csvmap=fastq__csvmap, 
                   str_format="{sample_path}",
                   **wildcards)
    print("fastq_read: {}".format(fastq_read()))
    
def csvmap__format_str_from_query_dict(csvmap, str_format="", **query_dict):
    #
    # Queries a CSVMap object based on a given dictionary.
    #
    return set([ str_format.format(**_cmap)
                 for _cmap in csvmap.query_dict(**query_dict)
               ])

# -----------------
# Link fastq reads
# -----------------
localrules: fastq__linkFastqRead
rule fastq__linkFastqRead:
  #
  # Links original fastq file to the project directory.
  #
  input:
    #samples_map = fastq__samples_map,
    fastq_read = lambda wildcards: csvmap__format_str_from_query_dict(
                   csvmap=fastq__csvmap, 
                   str_format="{sample_path}",
                   **wildcards)
  output: 
    primary    = fastq__chunk_format + ".fastq.gz"
  shell:"""
    ln.rel {input.fastq_read} {output.primary} 
  """

# ---------------
# Fastq Quality
# ---------------
FASTQC_CORES = 6
rule fastq__fastqc_file:
  input:
      fastq_in= "{prefix}.fastq.gz"
  output:
      primary= "{prefix}.fastqc.html"
  shell:"""
    fastqc -o $(dirname {input[fastq_in]}) -t {FASTQC_CORES} {input[fastq_in]}
  """ 
